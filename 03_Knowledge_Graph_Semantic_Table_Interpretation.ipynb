{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7fe2d0795cb1de2",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Exercise 3\n",
    "# Semantic Table Interpretation\n",
    "\n",
    "The following Jupyter Notebook contains coding tasks for Exercise 3. Fill up the code cells and execute to show output.\n",
    "For this exercise, Pandas Library is required. For library reference, check for [Pandas Documentation](https://pandas.pydata.org/pandas-docs/stable/user_guide/index.html#user-guide). Also, check on [Pandas Cheatsheet](https://pandas.pydata.org/Pandas_Cheat_Sheet.pdf).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb72168571cede08",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-31T11:54:16.995491Z",
     "start_time": "2023-10-31T11:54:16.968698Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Install Pandas\n",
    "# !pip install pandas\n",
    "\n",
    "# Required Libraries\n",
    "import pandas as pd\n",
    "import requests\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e291226048746d7d",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Task 3\n",
    "## Column Data Type Detection\n",
    "\n",
    "Task 3.1 : Given column are set of values, write a function to predict data types in the column and return result. For reference, look up on Lecture 3, pg-45\n",
    "\n",
    "<img src=\"images/algorithm.png\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cfb6f8e27733de91",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-04T16:30:53.647059Z",
     "start_time": "2023-11-04T16:30:53.644058Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'float'>\n"
     ]
    }
   ],
   "source": [
    "col = [\"6\", \"1.8\", \"1.25\"]\n",
    "data_types = [int, float, str]\n",
    "\n",
    "# Code Here\n",
    "def predictDataType(records):\n",
    "    types = {}\n",
    "    for data_type in data_types:\n",
    "        types[data_type] = 0\n",
    "    for value in records:\n",
    "        for data_type in data_types:\n",
    "            try:\n",
    "                data_type(value)\n",
    "                types[data_type] = types[data_type] + 1\n",
    "            except ValueError:\n",
    "                pass\n",
    "    for data_type in data_types:\n",
    "        if types[data_type] == len(records):\n",
    "            return data_type\n",
    "    return None\n",
    "\n",
    "res = predictDataType(col)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f7bde6021b6ce46",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Task 5\n",
    "### Automatic Semantic Table Interpretation\n",
    "\n",
    "For this task requires API requests using 'requests' library. The table is provided as 'table2.csv'. For this task, the table is a multi-subject relational table\n",
    "> - the first column is the subject column\n",
    "> - the first two columns contain entities\n",
    "> - the third column contains numbers\n",
    "\n",
    "Using the file, perform the following tasks. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec6f5e5308070e72",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Task 5.1\n",
    "Using MTab API provided, perform entity search on each cell and take out the top-ranked entity from results.\n",
    "Refer to [MTab GitHub Documentation](https://github.com/phucty/mtab_tool/blob/master/docs/mtabes.md). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3acd4e465e479869",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-31T11:54:34.155866Z",
     "start_time": "2023-10-31T11:54:17.117310Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/amirrezaalasti/.pyenv/versions/3.9.13/lib/python3.9/site-packages/urllib3/connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'mtab.kgraph.jp'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "/Users/amirrezaalasti/.pyenv/versions/3.9.13/lib/python3.9/site-packages/urllib3/connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'mtab.kgraph.jp'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "/Users/amirrezaalasti/.pyenv/versions/3.9.13/lib/python3.9/site-packages/urllib3/connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'mtab.kgraph.jp'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "/Users/amirrezaalasti/.pyenv/versions/3.9.13/lib/python3.9/site-packages/urllib3/connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'mtab.kgraph.jp'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "/Users/amirrezaalasti/.pyenv/versions/3.9.13/lib/python3.9/site-packages/urllib3/connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'mtab.kgraph.jp'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "/Users/amirrezaalasti/.pyenv/versions/3.9.13/lib/python3.9/site-packages/urllib3/connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'mtab.kgraph.jp'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Berlin': None, 'Paris': None, 'Milano': None, 'Germany': None, 'France': None, 'Italy': None}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "api_endpoint = \"https://mtab.kgraph.jp/api/v1/search?\"\n",
    "wd_endpoint = \"http://www.wikidata.org/entity/\"\n",
    "\n",
    "def entitySearch(term):\n",
    "    params = {\n",
    "        \"q\": term,\n",
    "        \"m\":\"a\",\n",
    "        \"limit\": \"3\",\n",
    "        \"info\": \"1\"\n",
    "    }\n",
    "    resp = requests.get(api_endpoint, verify=False, params=params)\n",
    "    if resp.status_code == 200:\n",
    "        r_data = resp.json()\n",
    "        if r_data['status'] == \"Success\" and int(r_data['total']) > 0:\n",
    "            hits = pd.DataFrame(r_data['hits'])\n",
    "            hits['score'] = hits['score'].astype(float)\n",
    "            max_score_idx = hits['score'].idxmax()\n",
    "            dp_url = hits.iloc[max_score_idx].dp\n",
    "            wd_id = hits.iloc[max_score_idx].id\n",
    "            return (dp_url, wd_id)\n",
    "    return \n",
    "\n",
    "# Code Here\n",
    "data = pd.read_csv(\"data/table2.csv\", header=None)\n",
    "entity_list = {}\n",
    "\n",
    "for term in data[0]:\n",
    "    entity_list[term] = entitySearch(term)\n",
    "    \n",
    "for term in data[1]:\n",
    "    entity_list[term] = entitySearch(term)\n",
    "    \n",
    "print(entity_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dff4d1346a46d81",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Task 5.2 \n",
    "For each pair of subject column, run the following query by replacing tags (#ENT1, #ENT2) with respective Wikidata URLs. Then run the queries with SPARQLwrapper and decide the property based on majority voting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "528f70a0c6389e65",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-31T12:09:45.453186Z",
     "start_time": "2023-10-31T12:09:45.443008Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# For majority voting\n",
    "def majorityVoting(list_of_values):\n",
    "    \"\"\"Counts the number of times each value appears in a list.\n",
    "  \n",
    "    Args:\n",
    "      list_of_values: A list of values.\n",
    "  \n",
    "    Returns:\n",
    "      A dictionary mapping each value to the number of times it appears in the list.\n",
    "    \"\"\"\n",
    "\n",
    "    value_counts = {}\n",
    "    for value in list_of_values:\n",
    "        if value in value_counts:\n",
    "            value_counts[value] += 1\n",
    "        else:\n",
    "            value_counts[value] = 1\n",
    "\n",
    "    return value_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f235e887a31174cd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-31T12:09:48.016908Z",
     "start_time": "2023-10-31T12:09:47.561971Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Berlin -> http://www.wikidata.org/prop/direct/P17 -> Germany\n",
      "Paris -> http://www.wikidata.org/prop/direct/P17 -> France\n",
      "Milano -> http://www.wikidata.org/prop/direct/P17 -> Italy\n",
      "{'http://www.wikidata.org/prop/direct/P17': 3}\n"
     ]
    }
   ],
   "source": [
    "# Example template\n",
    "wd_endpoint = \"https://query.wikidata.org/sparql\"\n",
    "\n",
    "# Code Here\n",
    "sparql_endpoint = SPARQLWrapper(wd_endpoint)\n",
    "sparql_endpoint.setReturnFormat(JSON)\n",
    "ent2ent= []\n",
    "\n",
    "for ent1, ent2 in zip(data[0], data[1]):\n",
    "    query1 = \"\"\"\n",
    "        SELECT ?property WHERE {\n",
    "          wd:#ENT1 ?property wd:#ENT2 .\n",
    "        }\n",
    "    \"\"\"\n",
    "    query1 = query1.replace(\"#ENT1\", entity_list[ent1][1])\n",
    "    query1 = query1.replace(\"#ENT2\", entity_list[ent2][1])\n",
    "    sparql_endpoint.setQuery(query1)\n",
    "    prop = sparql_endpoint.query().convert()\n",
    "    prop = prop[\"results\"][\"bindings\"][0]['property'][\"value\"]\n",
    "    ent2ent.append(prop)\n",
    "    print(f\"{ent1} -> {prop} -> {ent2}\")\n",
    "  \n",
    "print(majorityVoting(ent2ent))  \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4253d35c42496bdf",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Task 5.3\n",
    "For each pair of subject columns and any other entity column, Replace the tags (#ENT1, #NUM) with respective values and run the query in SPARQLWrapper. Decide the property based on majority voting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ead36f0c2d2c7c71",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-31T12:12:40.942708Z",
     "start_time": "2023-10-31T12:12:40.697234Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Berlin -http://www.wikidata.org/prop/direct/P1082-> 3755251\n",
      "Paris -[]-> 2140000\n",
      "Milano -[]-> 1366180\n",
      "{'http://www.wikidata.org/prop/direct/P1082': 1}\n"
     ]
    }
   ],
   "source": [
    "# Code Here\n",
    "ent2num = []\n",
    "\n",
    "for idx, ent_key in enumerate(data[0]):\n",
    "    num = str(data[2][idx])\n",
    "    query2 = \"\"\"\n",
    "        SELECT ?property WHERE {\n",
    "           wd:#ENT1 ?property \"#NUM\"^^xsd:decimal \n",
    "        }\n",
    "    \"\"\"\n",
    "    query2 = query2.replace(\"#ENT1\", entity_list[ent_key][1])\n",
    "    query2 = query2.replace(\"#NUM\", num)\n",
    "    sparql_endpoint.setQuery(query2)\n",
    "    prop2 = sparql_endpoint.query().convert()\n",
    "    prop2 = prop2[\"results\"][\"bindings\"]\n",
    "    if len(prop2) > 0:\n",
    "        prop2 = prop2[0][\"property\"][\"value\"]\n",
    "        ent2num.append(prop2)\n",
    "    print(f\"{ent_key} -{prop2}-> {num}\")\n",
    "    \n",
    "print(majorityVoting(ent2num))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42928364236d6723",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Task 5.4 \n",
    "Consider the following query template. Run the query for each entity and for each entity types, perform majority voting to detect type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "673fe8ca92145f85",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-31T13:22:57.301110Z",
     "start_time": "2023-10-31T13:22:56.505211Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                        Berlin  Paris  Milano\n",
      "http://www.wikidata.org/entity/Q200250     1.0    1.0     1.0\n",
      "\n",
      "\n",
      "                                         Germany  France  Italy\n",
      "http://www.wikidata.org/entity/Q6256         1.0       1    1.0\n",
      "http://www.wikidata.org/entity/Q3624078      1.0       1    1.0\n"
     ]
    }
   ],
   "source": [
    "# Code Here\n",
    "col1 = {}\n",
    "\n",
    "for key in data[0]:\n",
    "    entity = entity_list[key]\n",
    "    query3 = \"\"\"\n",
    "        SELECT ?type WHERE {\n",
    "          wd:#ENT1 wdt:P31 ?type .\n",
    "        }\n",
    "    \"\"\".replace(\"#ENT1\", entity[1])\n",
    "    sparql_endpoint.setQuery(query3)\n",
    "    results = sparql_endpoint.query().convert()[\"results\"][\"bindings\"]\n",
    "    results = [uri['type']['value'] for uri in results]\n",
    "    col1[key] = majorityVoting(results)\n",
    "\n",
    "col2 = {}\n",
    "\n",
    "for key in data[1]:\n",
    "    entity = entity_list[key]\n",
    "    query3 = \"\"\"\n",
    "        SELECT ?type WHERE {\n",
    "          wd:#ENT1 wdt:P31 ?type .\n",
    "        }\n",
    "    \"\"\".replace(\"#ENT1\", entity[1])\n",
    "    sparql_endpoint.setQuery(query3)\n",
    "    results = sparql_endpoint.query().convert()[\"results\"][\"bindings\"]\n",
    "    results = [uri['type']['value'] for uri in results]\n",
    "    col2[key] = majorityVoting(results)\n",
    "    \n",
    "col1 = pd.DataFrame(col1).dropna()\n",
    "print(col1)\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "col2 = pd.DataFrame(col2).dropna()\n",
    "print(col2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
